{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import random\n",
    "import time\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = pd.read_csv('../datasets/raw_datasets/df_train_copy_preprocessed.csv')\n",
    "df_test = pd.read_csv('../datasets/raw_datasets/df_test_preprocessed.csv')\n",
    "X_train = pd.read_csv('../datasets/raw_datasets/X_train.csv')\n",
    "X_val = pd.read_csv('../datasets/raw_datasets/X_val.csv')\n",
    "y_train = pd.read_csv('../datasets/raw_datasets/y_train.csv')\n",
    "y_val = pd.read_csv('../datasets/raw_datasets/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Features\n",
    "features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Group',\n",
    "       'Cabin_number', 'HomePlanet_Earth', 'HomePlanet_Europa', 'HomePlanet_Mars',\n",
    "       'CryoSleep_False', 'CryoSleep_True', 'Destination_55 Cancri e',\n",
    "       'Destination_PSO J318.5-22', 'Destination_TRAPPIST-1e', 'VIP_False',\n",
    "       'VIP_True', 'Cabin_deck_A', 'Cabin_deck_B', 'Cabin_deck_C',\n",
    "       'Cabin_deck_D', 'Cabin_deck_E', 'Cabin_deck_F', 'Cabin_deck_G',\n",
    "       'Cabin_deck_T', 'Cabin_side_P', 'Cabin_side_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3954, number of negative: 3869\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505433 -> initscore=0.021732\n",
      "[LightGBM] [Info] Start training from score 0.021732\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3946, number of negative: 3877\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504410 -> initscore=0.017641\n",
      "[LightGBM] [Info] Start training from score 0.017641\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3937, number of negative: 3886\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503260 -> initscore=0.013039\n",
      "[LightGBM] [Info] Start training from score 0.013039\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3952, number of negative: 3872\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505112 -> initscore=0.020451\n",
      "[LightGBM] [Info] Start training from score 0.020451\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3925, number of negative: 3899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1902\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501662 -> initscore=0.006646\n",
      "[LightGBM] [Info] Start training from score 0.006646\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3930, number of negative: 3894\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502301 -> initscore=0.009203\n",
      "[LightGBM] [Info] Start training from score 0.009203\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1901\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3945, number of negative: 3879\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504218 -> initscore=0.016872\n",
      "[LightGBM] [Info] Start training from score 0.016872\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1901\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n",
      "[LightGBM] [Info] Start training from score 0.014826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3932, number of negative: 3892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502556 -> initscore=0.010225\n",
      "[LightGBM] [Info] Start training from score 0.010225\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=619)\n",
    "cv_results = cross_validate(model, df_train_copy[features], df_train_copy[\"Transported\"], cv=kf, return_train_score=True )\n",
    "\n",
    "model_time = cv_results['fit_time'].mean()\n",
    "model_train_accuracy_mean = cv_results['train_score'].mean()\n",
    "model_test_accuracy_mean = cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1694054365158081\n",
      "0.8911384538852584\n",
      "0.814445987593085\n"
     ]
    }
   ],
   "source": [
    "print(model_time)\n",
    "print(model_train_accuracy_mean)\n",
    "print(model_test_accuracy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1903\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/miniconda3/envs/github_classification/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ahmad/miniconda3/envs/github_classification/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8971814782858787\n",
      "0.8056354226566993\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_val)\n",
    "\n",
    "score_train = metrics.accuracy_score(y_train, pred_train)\n",
    "score_test = metrics.accuracy_score(y_val, pred_test)\n",
    "\n",
    "print(score_train)\n",
    "print(score_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
